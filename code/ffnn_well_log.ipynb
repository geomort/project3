{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "671e5d96",
   "metadata": {},
   "source": [
    "# Regression using Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80bc267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from source.ffnn_model import WellLogFFNN\n",
    "from source.ffnn_well_data_preprocessing import load_log_data\n",
    "\n",
    "# Reproducibility, gotten from project 2\n",
    "NP_RANDOM_SEED = 42\n",
    "torch.manual_seed(NP_RANDOM_SEED)\n",
    "np.random.seed(NP_RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b1299",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_val, y_val), (X_test, y_test), x_scaler, y_scaler = load_log_data(None)\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_val:\",   X_val.shape)\n",
    "print(\"X_test:\",  X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6dd8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics of y_train\n",
    "print(\"y_train min:\", y_train.min().item())\n",
    "print(\"y_train max:\", y_train.max().item())\n",
    "print(\"y_train mean:\", y_train.mean().item())\n",
    "print(\"y_train std:\", y_train.std().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5016eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Defining model and training function.\n",
    "\n",
    "The model is a feedforward neural network defined in source/ffnn_model.py.\n",
    "\n",
    "The training function uses MSE loss and Adam optimizer.\n",
    "\n",
    "Code is adapted from project 2 part c.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "# Defining model\n",
    "def make_model(hidden_dims=(64, 64), dropout=0.2, activation=nn.ReLU):\n",
    "    return WellLogFFNN(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dims=hidden_dims,\n",
    "        dropout=dropout,\n",
    "        activation=activation,\n",
    "    )\n",
    "# Training function\n",
    "def train_model(\n",
    "    model,\n",
    "    X_train, y_train,\n",
    "    X_val,   y_val,\n",
    "    lr: float = 1e-3,\n",
    "    epochs: int = 100,\n",
    "    verbose: bool = False,\n",
    "):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_state_dict = None\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses   = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # ---- TRAIN ----\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        # ---- VALIDATION ----\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val)\n",
    "            val_loss = criterion(val_outputs, y_val).item()\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_state_dict = model.state_dict()\n",
    "\n",
    "        if verbose and (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1:4d} | Train MSE: {loss.item():.4f} | Val MSE: {val_loss:.4f}\")\n",
    "\n",
    "    # last best weights\n",
    "    if best_state_dict is not None:\n",
    "        model.load_state_dict(best_state_dict)\n",
    "\n",
    "    return model, best_val_loss, train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba443eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with different configurations and evaluating on test set\n",
    "configs = [\n",
    "    {\"name\": \"small_no_dropout\",  \"hidden_dims\": (32, 32),        \"lr\": 1e-3, \"dropout\": 0.0},\n",
    "    {\"name\": \"medium_dropout\",    \"hidden_dims\": (64, 64),        \"lr\": 1e-3, \"dropout\": 0.2},\n",
    "    {\"name\": \"deep_dropout\",      \"hidden_dims\": (128, 64, 32),   \"lr\": 1e-4, \"dropout\": 0.2},\n",
    "    {\"name\": \"medium_lr_high\",    \"hidden_dims\": (64, 64),        \"lr\": 1e-2, \"dropout\": 0.2},\n",
    "]\n",
    "\n",
    "results = []\n",
    "histories = {}\n",
    "\n",
    "for cfg in configs:\n",
    "    print(f\"\\n=== Training config: {cfg['name']} ===\")\n",
    "    print(f\"hidden_dims={cfg['hidden_dims']}, lr={cfg['lr']}, dropout={cfg['dropout']}\")\n",
    "\n",
    "    torch.manual_seed(NP_RANDOM_SEED)\n",
    "    np.random.seed(NP_RANDOM_SEED)\n",
    "\n",
    "    model = make_model(\n",
    "        hidden_dims=cfg[\"hidden_dims\"],\n",
    "        dropout=cfg[\"dropout\"],\n",
    "        activation=nn.ReLU,\n",
    "    )\n",
    "\n",
    "    model, best_val_mse, train_losses, val_losses = train_model(\n",
    "        model,\n",
    "        X_train, y_train,\n",
    "        X_val,   y_val,\n",
    "        lr=cfg[\"lr\"],\n",
    "        epochs=100,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # evaluate on test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_test = model(X_test)\n",
    "        test_mse = nn.MSELoss()(y_pred_test, y_test).item()\n",
    "\n",
    "    results.append({\n",
    "        \"name\":        cfg[\"name\"],\n",
    "        \"hidden_dims\": cfg[\"hidden_dims\"],\n",
    "        \"lr\":          cfg[\"lr\"],\n",
    "        \"dropout\":     cfg[\"dropout\"],\n",
    "        \"val_mse\":     best_val_mse,\n",
    "        \"test_mse\":    test_mse,\n",
    "    })\n",
    "\n",
    "    histories[cfg[\"name\"]] = {\n",
    "        \"train_losses\": train_losses,\n",
    "        \"val_losses\":   val_losses,\n",
    "    }\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe900c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.trial import Trial  \n",
    "\n",
    "\"\"\"Objective function for Optuna hyperparameter optimization.\"\"\"\n",
    "\n",
    "# Define objective function for Optuna\n",
    "def objective(trial):\n",
    "    (X_train, y_train), (X_val, y_val), (X_test, y_test), x_scaler, y_scaler = load_log_data(\n",
    "        random_state=42\n",
    "    )    \n",
    "    \n",
    "    \n",
    "    # Suggest hyperparameters\n",
    "    hidden_dim1 = trial.suggest_int(\"hidden_dim1\", 16, 256, step=16)\n",
    "    hidden_dim2 = trial.suggest_int(\"hidden_dim2\", 16, 256, step=16)\n",
    "    hidden_dim3 = trial.suggest_int(\"hidden_dim3\", 16, 256, step=16)\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 4)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.5, step=0.1)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "    \n",
    "    # Build hidden_dims tuple based on n_layers\n",
    "    hidden_dims_list = [hidden_dim1, hidden_dim2, hidden_dim3][:n_layers]\n",
    "    hidden_dims = tuple(hidden_dims_list)\n",
    "    \n",
    "    # Reset seeds for reproducibility\n",
    "    torch.manual_seed(NP_RANDOM_SEED)\n",
    "    np.random.seed(NP_RANDOM_SEED)\n",
    "    \n",
    "    # Create and train model\n",
    "    model = make_model(\n",
    "        hidden_dims=hidden_dims,\n",
    "        dropout=dropout, \n",
    "        activation=nn.ReLU,\n",
    "    )\n",
    "    model, best_val_mse, _, _ = train_model(\n",
    "        model,\n",
    "        X_train, y_train,\n",
    "        X_val, y_val,\n",
    "        lr=lr,\n",
    "        epochs=100,\n",
    "        verbose=False,\n",
    "    )\n",
    "    \n",
    "    return best_val_mse\n",
    "\n",
    "# Create and run Optuna study\n",
    "print(\"Starting Optuna hyperparameter optimization...\")\n",
    "study = optuna.create_study(\n",
    "    study_name=\"ffnn_regression_rs42_new\",\n",
    "    storage=\"sqlite:///optuna_study.db\",\n",
    "    direction=\"minimize\",\n",
    "    load_if_exists=False,\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "# Get best trial\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OPTUNA OPTIMIZATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best validation MSE: {best_trial.value:.6f}\")\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab9d67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting a heatmap of the optuna results\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "optuna_df = study.trials_dataframe()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(optuna_df.select_dtypes(include=['number']).corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap of Optuna Trial Parameters and Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58000935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Extract best hyperparameters from Optuna ===\n",
    "best_params = best_trial.params\n",
    "\n",
    "# Build hidden layers tuple\n",
    "n_layers = best_params[\"n_layers\"]\n",
    "best_hidden_dims = tuple([\n",
    "    best_params[\"hidden_dim1\"],\n",
    "    best_params[\"hidden_dim2\"],\n",
    "    best_params[\"hidden_dim3\"],\n",
    "][:n_layers])\n",
    "\n",
    "best_dropout = best_params[\"dropout\"]\n",
    "best_lr = best_params[\"lr\"]\n",
    "\n",
    "print(\"Using hidden_dims =\", best_hidden_dims)\n",
    "print(\"dropout =\", best_dropout)\n",
    "print(\"learning rate =\", best_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a2a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred_test_unscaled = y_scaler.inverse_transform(y_pred_test.reshape(-1, 1))\n",
    "y_test_unscaled      = y_scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Plotting train/val loss curves for best config\n",
    "best_name = results_df.sort_values(\"val_mse\").iloc[0][\"name\"]\n",
    "print(\"Best config:\", best_name)\n",
    "\n",
    "train_losses = histories[best_name][\"train_losses\"]\n",
    "val_losses   = histories[best_name][\"val_losses\"]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_losses, label=\"Train MSE\")\n",
    "plt.plot(val_losses,   label=\"Val MSE\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE loss\")\n",
    "plt.legend()\n",
    "plt.title(f\"Train/val loss – {best_name}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda2ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Optuna best trial to rebuild & retrain the model, then plot preds vs true\n",
    "params = best_trial.params\n",
    "n_layers = params.get(\"n_layers\", 2)\n",
    "hidden_dims = tuple([params[\"hidden_dim1\"], params[\"hidden_dim2\"], params[\"hidden_dim3\"]][:n_layers])\n",
    "dropout = params.get(\"dropout\", 0.0)\n",
    "lr = params.get(\"lr\", 1e-3)\n",
    "\n",
    "print(\"Best Optuna params:\", params)\n",
    "print(\"Using hidden_dims =\", hidden_dims, \"dropout =\", dropout, \"lr =\", lr)\n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(NP_RANDOM_SEED)\n",
    "np.random.seed(NP_RANDOM_SEED)\n",
    "\n",
    "# Build and train model using Optuna params\n",
    "model = make_model(\n",
    "    hidden_dims=hidden_dims,\n",
    "    dropout=dropout,\n",
    "    activation=nn.ReLU,\n",
    ")\n",
    "model, _, _, _ = train_model(\n",
    "    model,\n",
    "    X_train, y_train,\n",
    "    X_val,   y_val,\n",
    "    lr=lr,\n",
    "    epochs=100,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# Predictions on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_test = model(X_test).cpu().numpy()\n",
    "y_true_test = y_test.cpu().numpy()\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure()\n",
    "plt.scatter(y_true_test, y_pred_test, alpha=0.5)\n",
    "plt.xlabel(\"True SONIC\")\n",
    "plt.ylabel(\"Predicted SONIC\")\n",
    "plt.title(\"Predicted vs true SONIC (test set) — Optuna best\")\n",
    "plt.plot([y_true_test.min(), y_true_test.max()],\n",
    "         [y_true_test.min(), y_true_test.max()], color=\"red\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372812cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculating R² score.\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "seeds = [0, 1, 2, 3, 4]\n",
    "scores = []\n",
    "\n",
    "for seed in seeds:\n",
    "    # 1. new random split\n",
    "    (X_train, y_train), (X_val, y_val), (X_test, y_test), x_scaler, y_scaler = load_log_data(None)\n",
    "\n",
    "    # 2. train model with same hyperparameters\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    model = make_model(  # use best params fra Optuna\n",
    "        hidden_dims = hidden_dims,\n",
    "        dropout = best_dropout,\n",
    "        activation = nn.ReLU,\n",
    "    )\n",
    "\n",
    "    model, best_val_mse, train_losses, val_losses = train_model(\n",
    "        model,\n",
    "        X_train, y_train,\n",
    "        X_val,   y_val,\n",
    "        lr=best_lr,\n",
    "        epochs=100,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # 3. evaluate on test\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_test = model(X_test)\n",
    "\n",
    "    r2 = r2_score(\n",
    "        y_test.numpy().ravel(),\n",
    "        y_pred_test.numpy().ravel()\n",
    "    )\n",
    "    print(f\"Seed {seed}: R² = {r2:.4f}\")\n",
    "    scores.append(r2)\n",
    "\n",
    "print(\"R² scores:\", scores)\n",
    "print(\"Mean R²:\", np.mean(scores))\n",
    "print(\"Std  R²:\", np.std(scores))\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(scores, bins='auto', alpha=0.7)\n",
    "plt.xlabel(\"R² score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of R² scores over different random seeds\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927efaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Convert tensors to numpy\n",
    "X_tr = X_train.numpy()\n",
    "y_tr = y_train.numpy().ravel()\n",
    "X_te = X_test.numpy()\n",
    "y_te = y_test.numpy().ravel()\n",
    "\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_tr, y_tr)\n",
    "\n",
    "ridge_pred = ridge.predict(X_te)\n",
    "\n",
    "ridge_mse = mean_squared_error(y_te, ridge_pred)\n",
    "ridge_r2  = r2_score(y_te, ridge_pred)\n",
    "\n",
    "print(\"Ridge baseline:\")\n",
    "print(\"Test MSE:\", ridge_mse)\n",
    "print(\"Test R²:\", ridge_r2)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(y_te, ridge_pred, alpha=0.5)\n",
    "plt.xlabel(\"True SONIC\")\n",
    "plt.ylabel(\"Predicted SONIC\")\n",
    "plt.title(\"Predicted vs true SONIC (test set) — Ridge baseline\")\n",
    "plt.plot([y_te.min(), y_te.max()],\n",
    "            [y_te.min(), y_te.max()], color=\"red\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
