learning_rate = 0.001

if PRETRAINED_MODEL:
    optimizer = torch.optim.Adam(model.fc.parameters(), lr=learning_rate, weight_decay=1e-4)  # only updates weights for fully connected layer
else:
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)

loss_fn = nn.CrossEntropyLoss()
epochs = 50 #2#50#30



Training dataset
Per-class counts:
 0            ants: 1029
 1            bees: 1101
 2         beetles: 857
 3    caterpillars: 906
 4      earthworms: 717
 5         earwigs: 939
 6    grasshoppers: 1044
 7           moths: 1059
 8           slugs: 797
 9          snails: 1079
10           wasps: 1011
11         weevils: 960

Validation dataset
Per-class counts:
 0            ants: 95
 1            bees: 99
 2         beetles: 89
 3    caterpillars: 77
 4      earthworms: 51
 5         earwigs: 91
 6    grasshoppers: 98
 7           moths: 100
 8           slugs: 77
 9          snails: 98
10           wasps: 116
11         weevils: 104

Test dataset
Per-class counts:
 0            ants: 54
 1            bees: 40
 2         beetles: 41
 3    caterpillars: 46
 4      earthworms: 27
 5         earwigs: 59
 6    grasshoppers: 38
 7           moths: 47
 8           slugs: 46
 9          snails: 44
10           wasps: 46
11         weevils: 58






{'accuracy': 0.8644688644688645,
 'macro_f1': 0.8590787649154663,
 'precision_per_class': array([0.877193  , 0.902439  , 0.7222222 , 0.7708333 , 0.9047619 ,
        0.82978725, 0.78723407, 0.9782609 , 0.7407407 , 0.95555556,
        0.8979592 , 1.        ], dtype=float32),
 'recall_per_class': array([0.9259259 , 0.925     , 0.63414633, 0.8043478 , 0.7037037 ,
        0.66101694, 0.9736842 , 0.9574468 , 0.8695652 , 0.97727275,
        0.95652175, 0.94827586], dtype=float32),
 'confusion_matrix': array([[50,  1,  1,  0,  0,  1,  0,  0,  1,  0,  0,  0],
        [ 0, 37,  0,  0,  0,  2,  0,  0,  0,  0,  1,  0],
        [ 2,  3, 26,  0,  0,  2,  2,  0,  4,  0,  2,  0],
        [ 0,  0,  1, 37,  1,  2,  2,  0,  2,  0,  1,  0],
        [ 0,  0,  1,  3, 19,  0,  1,  0,  3,  0,  0,  0],
        [ 4,  0,  3,  5,  1, 39,  4,  1,  2,  0,  0,  0],
        [ 0,  0,  0,  0,  0,  0, 37,  0,  1,  0,  0,  0],
        [ 0,  0,  1,  1,  0,  0,  0, 45,  0,  0,  0,  0],
        [ 0,  0,  1,  2,  0,  0,  0,  0, 40,  2,  1,  0],
        [ 0,  0,  0,  0,  0,  0,  0,  0,  1, 43,  0,  0],
        [ 1,  0,  0,  0,  0,  1,  0,  0,  0,  0, 44,  0],
        [ 0,  0,  2,  0,  0,  0,  1,  0,  0,  0,  0, 55]])}





# Settings
yaml_path = Path.cwd().parent / "datasets" / "agropest12" / "data.yaml"

# Settings for retreiving images. Set None for all images or an integer for subset for testing code
subset_classes = None #['Ants', 'Snails'] # None or list of classes. Example ['Ants', 'Snails']
n_images_train  = None #None for all images
n_images_valid = None # int(n_images_train * 0.2) #20% of number of images for train #None for all images
n_images_test = None #int(n_images_train * 0.2) #20% of number of images for train #None for all images


def get_batch_size(n_images_train=None):
    if torch.cuda.is_available():
        gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1024**3  # in GB
        if gpu_mem > 12:
            default_large = 128
        else:
            default_large = 64
    else:
        default_large = 32

    if n_images_train is None:
        return default_large
    elif n_images_train < 20:
        return 16
    elif n_images_train < 100:
        return 32
    else:
        return default_large

batch_size = get_batch_size(n_images_train)


PRETRAINED_MODEL = True   # Use pretrained model and weights, else custom
if PRETRAINED_MODEL:
    NORMALIZE = 'ImageNet' #'auto' -  load if file exists, else compute and save, 'compute' - always recompute and overwrite file., 'load' - load from file. 'ImageNet' - use ImageNet values
else:
    NORMALIZE = 'load'
NORMALIZE_CACHE_PATH =  Path.cwd().parent / "datasets" / "agropest12" / "cache" / "agropest12_norm.json"

IMG_SIZE= (224,224) # must use (224,224) to match imagenet            #(128, 128) # # # # Image size for CNN (transform)
CROP_MODE = 'largest'# 'largest' #'largest'  # 'none' or 'largest  # largest extracts part of image where largest object is located. Some images have mostly background and small portion of object

DEBUG = False # Print debug info for functions
QUALITY_CONTROL = True # print and plot information for quality control
SAVE_MODELS = True
SHOW_PLOT = True
SAVE_FIGURE = True
COMPUTE_AVERAGE_IMG_SIZE = False


# Paths fir saving figures and models
current_dir = Path.cwd()
parent_dir = current_dir.parent

# Directory for saving figures
figures_path = parent_dir / "figures"
figures_path.mkdir(parents=True, exist_ok=True)

# Directory for saving models and summaries
models_path = parent_dir / "models"
models_path.mkdir(parents=True, exist_ok=True)


# Current timestamp for files
timestamp = datetime.now().strftime("%Y-%m-%d-%H-%M")



